{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/notebooks/katas/algorithms/LinearRegression_Scratch.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This is a self-correcting exercise generated by [nbgrader](https://github.com/jupyter/nbgrader). \n",
    "\n",
    "Fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Run subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kata: Code Linear Regression From Scratch\n",
    "\n",
    "In this kata, you'll code various linear regression algorithms and compare them to some of scikit-learn's linear regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plots\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML packages (edit this list if needed)\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate planar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_intercept = 4\n",
    "true_slope = 3\n",
    "\n",
    "# Generate linear-looking data with noise\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# add x0 = 1 to each sample\n",
    "X = np.c_[np.ones((100, 1)), X]\n",
    "\n",
    "print(f'X: {X.shape}. y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data (only x1)\n",
    "plt.plot(X[:,1], y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Using the normal equation, compute the theta vector that minimizes loss into the `theta_best` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5941436dbc2ddaf3535c9e950e3498b1",
     "grade": false,
     "grade_id": "cell-8b0138760e3b7131",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6904dc889b8fcfe43cead09b97693842",
     "grade": true,
     "grade_id": "cell-3b660b712c1c825c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "normal_intercept = theta_best[0][0]\n",
    "normal_slope = theta_best[1][0]\n",
    "print(f'Intercept: {normal_intercept}. Slope: {normal_slope}')\n",
    "\n",
    "assert np.abs(true_intercept - normal_intercept) < 0.5\n",
    "assert np.abs(true_slope - normal_slope) < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 test samples\n",
    "X_test = np.array([[0], [2]])\n",
    "# add x0 = 1 to each sample\n",
    "X_test = np.c_[np.ones((2, 1)), X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Use the model to predict values for the test samples. Store the result in variable `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4094bef9e6eee51c25d5a91cbff39d17",
     "grade": false,
     "grade_id": "cell-6264901b299337ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5c1f12059e468d004a505ac247b1a32",
     "grade": true,
     "grade_id": "cell-c937e69e2311ea21",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'y_pred: {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[:,1], y_pred, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "plt.plot(X[:,1], y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([0, 2, 0, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create a scikit-learn `LinearRegression` into the variable `model`. Use it to fit the data.\n",
    "\n",
    "Afterwards, compare its paramaters to those of your regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43dae0f64324dc7fa128b7b687b7f748",
     "grade": false,
     "grade_id": "cell-d9153fb070dfa6ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9eb9c2dd6952b5fb89053e75f552203d",
     "grade": true,
     "grade_id": "cell-486ba599c756e970",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sklearn_intercept = model.intercept_[0]\n",
    "sklearn_slope = model.coef_[0][1]\n",
    "print(f'Intercept: {sklearn_intercept}. Slope: {sklearn_slope}')\n",
    "\n",
    "assert np.abs(sklearn_intercept - normal_intercept) < 0.5\n",
    "assert np.abs(sklearn_slope - normal_slope) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Use the scikit-learn model to predict and print values for the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "080bcafe9c2ad17495d14d664a0d0a6b",
     "grade": false,
     "grade_id": "cell-b44a7432db69ee83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Approach: Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Complte the following function to implement Mean Squared Error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34536ac23692a2d8d68494c04c28e97e",
     "grade": false,
     "grade_id": "cell-b2b5eba005be50eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Complte the following code to implement batch gradient descent on the dataset, using the given hyperparameters.\n",
    "\n",
    "Print the loss value every 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de1f93263bd2d5a7e1835cbf558fbf62",
     "grade": false,
     "grade_id": "cell-d61bd7e54acc65dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.1 # learning rate\n",
    "n_iterations = 100\n",
    "m = 100\n",
    "\n",
    "theta_batch = np.random.randn(2,1) # random initialization\n",
    "print(f'Initial cost: {mse(y, X.dot(theta_batch))}')\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "488fe8034e1ef04cdd9fc570ae10e5f9",
     "grade": true,
     "grade_id": "cell-4f733fd7932337a0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "batch_intercept = theta_batch[0][0]\n",
    "batch_slope = theta_batch[1][0]\n",
    "print(f'Intercept: {batch_intercept}. Slope: {batch_slope}')\n",
    "\n",
    "assert np.abs(true_intercept - batch_intercept) < 0.5\n",
    "assert np.abs(true_slope - batch_slope) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Approach: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Complte the following code to implement stochastic gradient descent on the dataset, using the given hyperparameters.\n",
    "\n",
    "Print the loss value every 25 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10c99e92b0e80e709628415eb6231e3f",
     "grade": false,
     "grade_id": "cell-1cb6981295853e52",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.01 # learning rate\n",
    "n_iterations = 500\n",
    "m = 100\n",
    "\n",
    "theta_stochastic = np.random.randn(2,1) # random initialization\n",
    "print(f'Initial cost: {mse(y, X.dot(theta_stochastic))}')\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65fc9d83b89d4f57983be1e5d24a6ab9",
     "grade": true,
     "grade_id": "cell-06537d7ad534e193",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stochastic_intercept = theta_batch[0][0]\n",
    "stochastic_slope = theta_batch[1][0]\n",
    "print(f'Intercept: {stochastic_intercept}. Slope: {stochastic_slope}')\n",
    "\n",
    "assert np.abs(true_intercept - stochastic_intercept) < 0.5\n",
    "assert np.abs(true_slope - stochastic_slope) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create a scikit-learn `SGDRegressor` into the variable `model`. Use it to fit the data with the same hyperparameters as before.\n",
    "\n",
    "Afterwards, compare its paramaters to those of your regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c4b39133d8c93570a8ed1ba6e6da376",
     "grade": false,
     "grade_id": "cell-4270a529be207e00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f3562a3cd51463852042122527cac32",
     "grade": true,
     "grade_id": "cell-de18eaea25268f39",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sklearn_intercept = model.intercept_[0]\n",
    "sklearn_slope = model.coef_[0][1]\n",
    "print(f'Intercept: {sklearn_intercept}. Slope: {sklearn_slope}')\n",
    "\n",
    "assert np.abs(sklearn_intercept - normal_intercept) < 0.5\n",
    "assert np.abs(sklearn_slope - normal_slope) < 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Add assertions for model predictions.\n",
    "- Implement mini-batch SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
